{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "339a04cf-335a-4c61-bec8-916bf7fd3d3b"
   },
   "source": [
    "# Final Project Phase 4 - Home Credit Default Risk\n",
    "\n",
    "Spring 2024\n",
    "\n",
    "**Team Members:**\n",
    "- Glen Colletti\n",
    "- Alex Bordanca\n",
    "- Paul Miller\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKtFKCSXGwK3"
   },
   "source": [
    "# Abstract\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sn3pYxCPG38p"
   },
   "source": [
    "Our project aimed to predict loan repayment based on the data available at the time of application. To accomplish this the team down selected features in the application train data; implemented Recency, Frequency, and Monetary Value features; trained KNN, XGBoost, and Linear Regression models; as well as a deep learning model. We attempted to account for this by oversampling the minority class. \n",
    "\n",
    "Along the way we discovered an imbalance in the TARGET data causing our models to overpredict the majority class. The team identified correlations among the training set features, motivating us to select only one of any set of correlated features, reducing our model complexity with minimal impact on predictions. \n",
    "\n",
    "Other data anomalies included erroneous entries implying 1000-year credit history, and features with missing data. Mitigations for these anomalies included removal and imputing. By building our mitigations into data pipelines we were able to generalize our data preprocessing to our four model types with minimal rework. \n",
    "\n",
    "The Neural Network model yielded the strongest prediction performance with 60.5% F1 score and 60.5% ROC_AUC.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNJ_48sOTBbg"
   },
   "source": [
    "# Data Lineage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wX7nfUO3TE6t"
   },
   "source": [
    "The data originated from the Kaggle source. Throughout out the course of building, training, and refining the models, the underlying datasets underwent several transformations detailed below:\n",
    "- Appending to the initial train dataset via left join a dataset consisting of RFM (Recency, Frequency, Monetary Value) metrics extracted from the previous_applications dataset. The recency feature was calculated as the max (of DAYS_DECISION) to capture the most recent decision date; the frequency as the range of decision dates divided by the number of previous applications (flagged by distinct number of SK_ID_PREV grouped by SK_ID_CURR); and the monetary value was the sum of total amounts credited.\n",
    "- Within the pipelines, the data was further transformed to control for scaling issues and missing values. Numerical features' missing values were imputed with the median, and then standard scaled. Categorical features' missing values were imputed with the most frequent value within the column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RSkIe-ObFrva"
   },
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mtwjw19HFzrB"
   },
   "source": [
    "## delete me\n",
    "\n",
    "Neural Network/PyTorch (HCDR)\n",
    "-- Implement Neural Network (NN) model\n",
    "-- Experiment with at least 2 different Network architecture.\n",
    "-- Report neural network architecture in string form (e.g., 100 - 200 - Relu - 300 - Relu - 2 Softmax )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCwg3q-lm_QQ"
   },
   "source": [
    "To implement the Neural Network (Deep Learning) models a pipeline was adapted from Homework 11. The pipeline allowed us to train and test Neural Networks with dynamically defined hidden layers, optimization functions, activation functions, and loss functions. We improved upon the intial code base by adding F1 scores and AUC_ROC scores. A feature was added for the code to exit the epoch training cycle if subsequent models were no longer improving, indicating the model had converged.\n",
    "\n",
    "Intially we faced challenges with models hitting a performance ceiling around 92% accuracy. Upon further inspection we realized the models were learning to over predict the majoirty class becuase the TARGET data was 92% majority class. After added an oversampling step to the data processing to balance the majority and minority class the models hit a ceiling of ~60% performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LwsOfjODqARV"
   },
   "source": [
    "## Neural Network Pipeline\n",
    "\n",
    "\n",
    "![Image](NNBlockDiagram.PNG)\n",
    "\n",
    "![Image](NNBlockDiagram_train.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OlUYJGVlp-Un"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UW7aoGHn_NV"
   },
   "source": [
    "## Architecture 1\n",
    "\n",
    "We attempted many different configuration of neural networks, the first using Adadelta and a configuration in the form: 34-50-50-25-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "from pandasql import sqldf\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score,roc_auc_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "torch.manual_seed(0)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 307,511 rows in training set.\n",
      "Loaded 48,744 rows in testing set.\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('data/application_train.csv') #data we have the target class for\n",
    "test_data = pd.read_csv('data/application_test.csv') #data we need to predict target class for\n",
    "\n",
    "print (f'Loaded {train_data.shape[0]:,} rows in training set.')\n",
    "\n",
    "print (f'Loaded {test_data.shape[0]:,} rows in testing set.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1670214, 37)\n",
      "['AMT_ANNUITY', 'AMT_APPLICATION', 'AMT_CREDIT', 'AMT_DOWN_PAYMENT', 'AMT_GOODS_PRICE', 'CHANNEL_TYPE', 'CNT_PAYMENT', 'CODE_REJECT_REASON', 'DAYS_DECISION', 'DAYS_FIRST_DRAWING', 'DAYS_FIRST_DUE', 'DAYS_LAST_DUE', 'DAYS_LAST_DUE_1ST_VERSION', 'DAYS_TERMINATION', 'FLAG_LAST_APPL_PER_CONTRACT', 'HOUR_APPR_PROCESS_START', 'NAME_CASH_LOAN_PURPOSE', 'NAME_CLIENT_TYPE', 'NAME_CONTRACT_STATUS', 'NAME_CONTRACT_TYPE', 'NAME_GOODS_CATEGORY', 'NAME_PAYMENT_TYPE', 'NAME_PORTFOLIO', 'NAME_PRODUCT_TYPE', 'NAME_SELLER_INDUSTRY', 'NAME_TYPE_SUITE', 'NAME_YIELD_GROUP', 'NFLAG_INSURED_ON_APPROVAL', 'NFLAG_LAST_APPL_IN_DAY', 'PRODUCT_COMBINATION', 'RATE_DOWN_PAYMENT', 'RATE_INTEREST_PRIMARY', 'RATE_INTEREST_PRIVILEGED', 'SELLERPLACE_AREA', 'SK_ID_CURR', 'SK_ID_PREV', 'WEEKDAY_APPR_PROCESS_START']\n"
     ]
    }
   ],
   "source": [
    "PrevApp_data = pd.read_csv('data/previous_application.csv') #data from previous applications to Home Credit\n",
    "print(np.shape(PrevApp_data))\n",
    "col_names = PrevApp_data.columns.values.tolist()\n",
    "col_names.sort()\n",
    "print(col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join and filter previous application data with train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "      <th>RECENCY_FEATURE</th>\n",
       "      <th>FREQUENCY_FEATURE</th>\n",
       "      <th>MONETARY_VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-606.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>179055.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-746.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>1452573.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004</td>\n",
       "      <td>0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-815.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2625259.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-374.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>999832.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307506</th>\n",
       "      <td>456251</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>254700.0</td>\n",
       "      <td>27558.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-273.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307507</th>\n",
       "      <td>456252</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>269550.0</td>\n",
       "      <td>12001.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2497.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56821.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307508</th>\n",
       "      <td>456253</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>153000.0</td>\n",
       "      <td>677664.0</td>\n",
       "      <td>29979.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1909.0</td>\n",
       "      <td>471.0</td>\n",
       "      <td>41251.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307509</th>\n",
       "      <td>456254</td>\n",
       "      <td>1</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>171000.0</td>\n",
       "      <td>370107.0</td>\n",
       "      <td>20205.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-277.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>268879.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307510</th>\n",
       "      <td>456255</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>49117.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>3395448.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>307511 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       "0           100002       1         Cash loans           M            N   \n",
       "1           100003       0         Cash loans           F            N   \n",
       "2           100004       0    Revolving loans           M            Y   \n",
       "3           100006       0         Cash loans           F            N   \n",
       "4           100007       0         Cash loans           M            N   \n",
       "...            ...     ...                ...         ...          ...   \n",
       "307506      456251       0         Cash loans           M            N   \n",
       "307507      456252       0         Cash loans           F            N   \n",
       "307508      456253       0         Cash loans           F            N   \n",
       "307509      456254       1         Cash loans           F            N   \n",
       "307510      456255       0         Cash loans           F            N   \n",
       "\n",
       "       FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  \\\n",
       "0                    Y             0          202500.0    406597.5   \n",
       "1                    N             0          270000.0   1293502.5   \n",
       "2                    Y             0           67500.0    135000.0   \n",
       "3                    Y             0          135000.0    312682.5   \n",
       "4                    Y             0          121500.0    513000.0   \n",
       "...                ...           ...               ...         ...   \n",
       "307506               N             0          157500.0    254700.0   \n",
       "307507               Y             0           72000.0    269550.0   \n",
       "307508               Y             0          153000.0    677664.0   \n",
       "307509               Y             0          171000.0    370107.0   \n",
       "307510               N             0          157500.0    675000.0   \n",
       "\n",
       "        AMT_ANNUITY  ...  FLAG_DOCUMENT_21 AMT_REQ_CREDIT_BUREAU_HOUR  \\\n",
       "0           24700.5  ...                 0                        0.0   \n",
       "1           35698.5  ...                 0                        0.0   \n",
       "2            6750.0  ...                 0                        0.0   \n",
       "3           29686.5  ...                 0                        NaN   \n",
       "4           21865.5  ...                 0                        0.0   \n",
       "...             ...  ...               ...                        ...   \n",
       "307506      27558.0  ...                 0                        NaN   \n",
       "307507      12001.5  ...                 0                        NaN   \n",
       "307508      29979.0  ...                 0                        1.0   \n",
       "307509      20205.0  ...                 0                        0.0   \n",
       "307510      49117.5  ...                 0                        0.0   \n",
       "\n",
       "       AMT_REQ_CREDIT_BUREAU_DAY AMT_REQ_CREDIT_BUREAU_WEEK  \\\n",
       "0                            0.0                        0.0   \n",
       "1                            0.0                        0.0   \n",
       "2                            0.0                        0.0   \n",
       "3                            NaN                        NaN   \n",
       "4                            0.0                        0.0   \n",
       "...                          ...                        ...   \n",
       "307506                       NaN                        NaN   \n",
       "307507                       NaN                        NaN   \n",
       "307508                       0.0                        0.0   \n",
       "307509                       0.0                        0.0   \n",
       "307510                       0.0                        0.0   \n",
       "\n",
       "       AMT_REQ_CREDIT_BUREAU_MON AMT_REQ_CREDIT_BUREAU_QRT  \\\n",
       "0                            0.0                       0.0   \n",
       "1                            0.0                       0.0   \n",
       "2                            0.0                       0.0   \n",
       "3                            NaN                       NaN   \n",
       "4                            0.0                       0.0   \n",
       "...                          ...                       ...   \n",
       "307506                       NaN                       NaN   \n",
       "307507                       NaN                       NaN   \n",
       "307508                       1.0                       0.0   \n",
       "307509                       0.0                       0.0   \n",
       "307510                       2.0                       0.0   \n",
       "\n",
       "        AMT_REQ_CREDIT_BUREAU_YEAR  RECENCY_FEATURE  FREQUENCY_FEATURE  \\\n",
       "0                              1.0           -606.0                0.0   \n",
       "1                              0.0           -746.0              531.0   \n",
       "2                              0.0           -815.0                0.0   \n",
       "3                              NaN           -181.0               72.0   \n",
       "4                              0.0           -374.0              330.0   \n",
       "...                            ...              ...                ...   \n",
       "307506                         NaN           -273.0                0.0   \n",
       "307507                         NaN          -2497.0                0.0   \n",
       "307508                         1.0          -1909.0              471.0   \n",
       "307509                         0.0           -277.0               22.0   \n",
       "307510                         1.0           -171.0              102.0   \n",
       "\n",
       "        MONETARY_VALUE  \n",
       "0             179055.0  \n",
       "1            1452573.0  \n",
       "2              20106.0  \n",
       "3            2625259.5  \n",
       "4             999832.5  \n",
       "...                ...  \n",
       "307506         40455.0  \n",
       "307507         56821.5  \n",
       "307508         41251.5  \n",
       "307509        268879.5  \n",
       "307510       3395448.0  \n",
       "\n",
       "[307511 rows x 125 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_train_data = sqldf('''\n",
    "with rfm as (select\n",
    "  SK_ID_CURR, sum(AMT_CREDIT) as MONETARY_VALUE,\n",
    "  max(DAYS_DECISION) as RECENCY_FEATURE,\n",
    "  (max(DAYS_DECISION) - min(DAYS_DECISION))/COUNT(DISTINCT SK_ID_PREV) as FREQUENCY_FEATURE\n",
    "from PrevApp_data\n",
    "where AMT_CREDIT <> 0\n",
    "group by 1\n",
    ")\n",
    "select train.*, rfm.RECENCY_FEATURE, rfm.FREQUENCY_FEATURE, rfm.MONETARY_VALUE\n",
    "from train_data train\n",
    "left join rfm\n",
    "on train.SK_ID_CURR = rfm.SK_ID_CURR\n",
    "''')\n",
    "augmented_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_train_data = sqldf('''\n",
    "SELECT\n",
    "  TARGET,\n",
    "  FLOORSMAX_MEDI,\n",
    "  ELEVATORS_MEDI,\n",
    "  FLOORSMIN_MEDI,\n",
    "  AMT_CREDIT,\n",
    "  TOTALAREA_MODE,\n",
    "  DAYS_EMPLOYED,\n",
    "  OBS_30_CNT_SOCIAL_CIRCLE,\n",
    "  CNT_FAM_MEMBERs,\n",
    "  CNT_CHILDREN,\n",
    "  OWN_CAR_AGE,\n",
    "  DAYS_ID_PUBLISH,\n",
    "  DAYS_LAST_PHONE_CHANGE,\n",
    "  CODE_GENDER,\n",
    "  OCCUPATION_TYPE,\n",
    "  AMT_INCOME_TOTAL,\n",
    "  RECENCY_FEATURE,\n",
    "  FREQUENCY_FEATURE,\n",
    "  MONETARY_VALUE\n",
    "FROM\n",
    "  augmented_train_data\n",
    "\n",
    "''')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FLOORSMAX_MEDI</th>\n",
       "      <th>ELEVATORS_MEDI</th>\n",
       "      <th>FLOORSMIN_MEDI</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>TOTALAREA_MODE</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>OBS_30_CNT_SOCIAL_CIRCLE</th>\n",
       "      <th>CNT_FAM_MEMBERS</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>OWN_CAR_AGE</th>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <th>DAYS_LAST_PHONE_CHANGE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>OCCUPATION_TYPE</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>RECENCY_FEATURE</th>\n",
       "      <th>FREQUENCY_FEATURE</th>\n",
       "      <th>MONETARY_VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>568800.0</td>\n",
       "      <td>0.0392</td>\n",
       "      <td>-2329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-812</td>\n",
       "      <td>-1740.0</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>-1740.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23787.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>222768.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1623</td>\n",
       "      <td>0.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Low-skill Laborers</td>\n",
       "      <td>99000.0</td>\n",
       "      <td>-757.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40153.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>663264.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4458</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-3503</td>\n",
       "      <td>-856.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Drivers</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>-273.0</td>\n",
       "      <td>575.0</td>\n",
       "      <td>584536.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.0417</td>\n",
       "      <td>1575000.0</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>-1866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4208</td>\n",
       "      <td>-1805.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Sales staff</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>-797.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>464602.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>625500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-4262</td>\n",
       "      <td>-821.0</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>-111.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>601101.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48739</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>412560.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5169</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3399</td>\n",
       "      <td>-684.0</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>-683.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>254700.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48740</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>622413.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1149</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Sales staff</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>-770.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>394816.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48741</th>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>0.1663</td>\n",
       "      <td>-3037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1504</td>\n",
       "      <td>-838.0</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>-84.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>265033.665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48742</th>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>-2731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1364</td>\n",
       "      <td>-2308.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Managers</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>-577.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>637893.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48743</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>312768.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-4220</td>\n",
       "      <td>-327.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Core staff</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>-327.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>1166746.500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48744 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FLOORSMAX_MEDI  ELEVATORS_MEDI  FLOORSMIN_MEDI  AMT_CREDIT  \\\n",
       "0              0.1250             NaN             NaN    568800.0   \n",
       "1                 NaN             NaN             NaN    222768.0   \n",
       "2                 NaN             NaN             NaN    663264.0   \n",
       "3              0.3750            0.32          0.0417   1575000.0   \n",
       "4                 NaN             NaN             NaN    625500.0   \n",
       "...               ...             ...             ...         ...   \n",
       "48739             NaN             NaN             NaN    412560.0   \n",
       "48740             NaN             NaN             NaN    622413.0   \n",
       "48741          0.3333            0.16             NaN    315000.0   \n",
       "48742          0.6250            0.16             NaN    450000.0   \n",
       "48743             NaN             NaN             NaN    312768.0   \n",
       "\n",
       "       TOTALAREA_MODE  DAYS_EMPLOYED  OBS_30_CNT_SOCIAL_CIRCLE  \\\n",
       "0              0.0392          -2329                       0.0   \n",
       "1                 NaN          -4469                       0.0   \n",
       "2                 NaN          -4458                       0.0   \n",
       "3              0.3700          -1866                       0.0   \n",
       "4                 NaN          -2191                       0.0   \n",
       "...               ...            ...                       ...   \n",
       "48739             NaN          -5169                       1.0   \n",
       "48740             NaN          -1149                       2.0   \n",
       "48741          0.1663          -3037                       0.0   \n",
       "48742          0.1974          -2731                       0.0   \n",
       "48743             NaN           -633                       0.0   \n",
       "\n",
       "       CNT_FAM_MEMBERS  CNT_CHILDREN  OWN_CAR_AGE  DAYS_ID_PUBLISH  \\\n",
       "0                  2.0             0          NaN             -812   \n",
       "1                  2.0             0          NaN            -1623   \n",
       "2                  2.0             0          5.0            -3503   \n",
       "3                  4.0             2          NaN            -4208   \n",
       "4                  3.0             1         16.0            -4262   \n",
       "...                ...           ...          ...              ...   \n",
       "48739              1.0             0          NaN            -3399   \n",
       "48740              4.0             2          NaN            -3003   \n",
       "48741              3.0             1          4.0            -1504   \n",
       "48742              2.0             0          NaN            -1364   \n",
       "48743              2.0             0         22.0            -4220   \n",
       "\n",
       "       DAYS_LAST_PHONE_CHANGE CODE_GENDER     OCCUPATION_TYPE  \\\n",
       "0                     -1740.0           F                None   \n",
       "1                         0.0           M  Low-skill Laborers   \n",
       "2                      -856.0           M             Drivers   \n",
       "3                     -1805.0           F         Sales staff   \n",
       "4                      -821.0           M                None   \n",
       "...                       ...         ...                 ...   \n",
       "48739                  -684.0           F                None   \n",
       "48740                     0.0           F         Sales staff   \n",
       "48741                  -838.0           F                None   \n",
       "48742                 -2308.0           M            Managers   \n",
       "48743                  -327.0           F          Core staff   \n",
       "\n",
       "       AMT_INCOME_TOTAL  RECENCY_FEATURE  FREQUENCY_FEATURE  MONETARY_VALUE  \n",
       "0              135000.0          -1740.0                0.0       23787.000  \n",
       "1               99000.0           -757.0                0.0       40153.500  \n",
       "2              202500.0           -273.0              575.0      584536.500  \n",
       "3              315000.0           -797.0              252.0      464602.500  \n",
       "4              180000.0           -111.0              355.0      601101.000  \n",
       "...                 ...              ...                ...             ...  \n",
       "48739          121500.0           -683.0                0.0      254700.000  \n",
       "48740          157500.0           -770.0              420.0      394816.500  \n",
       "48741          202500.0            -84.0              377.0      265033.665  \n",
       "48742          225000.0           -577.0              432.0      637893.000  \n",
       "48743          135000.0           -327.0              148.0     1166746.500  \n",
       "\n",
       "[48744 rows x 18 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_test_data = sqldf('''\n",
    "with rfm as (select\n",
    "  SK_ID_CURR, sum(AMT_CREDIT) as MONETARY_VALUE,\n",
    "  max(DAYS_DECISION) as RECENCY_FEATURE,\n",
    "  (max(DAYS_DECISION) - min(DAYS_DECISION))/COUNT(DISTINCT SK_ID_PREV) as FREQUENCY_FEATURE\n",
    "from PrevApp_data\n",
    "where AMT_CREDIT <> 0\n",
    "group by 1\n",
    ")\n",
    "select train.*, rfm.RECENCY_FEATURE, rfm.FREQUENCY_FEATURE, rfm.MONETARY_VALUE\n",
    "from test_data train\n",
    "left join rfm\n",
    "on train.SK_ID_CURR = rfm.SK_ID_CURR\n",
    "''')\n",
    "filtered_test_data = sqldf('''\n",
    "SELECT\n",
    "  FLOORSMAX_MEDI,\n",
    "  ELEVATORS_MEDI,\n",
    "  FLOORSMIN_MEDI,\n",
    "  AMT_CREDIT,\n",
    "  TOTALAREA_MODE,\n",
    "  DAYS_EMPLOYED,\n",
    "  OBS_30_CNT_SOCIAL_CIRCLE,\n",
    "  CNT_FAM_MEMBERs,\n",
    "  CNT_CHILDREN,\n",
    "  OWN_CAR_AGE,\n",
    "  DAYS_ID_PUBLISH,\n",
    "  DAYS_LAST_PHONE_CHANGE,\n",
    "  CODE_GENDER,\n",
    "  OCCUPATION_TYPE,\n",
    "  AMT_INCOME_TOTAL,\n",
    "  RECENCY_FEATURE,\n",
    "  FREQUENCY_FEATURE,\n",
    "  MONETARY_VALUE\n",
    "FROM\n",
    "  augmented_test_data\n",
    "\n",
    "''')\n",
    "filtered_test_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers and pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplaceValuesTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        X_copy[self.column] = X_copy[self.column].apply(lambda x: 0 if x > 0 else x)\n",
    "        return X_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data\n",
    "X = filtered_train_data.drop(columns=['TARGET'])\n",
    "y = filtered_train_data['TARGET']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying naive oversampling minority to match class proportions between zero class and one class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=42)\n",
    "X_res, y_res = ros.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              TARGET\n",
      "count  307511.000000\n",
      "mean        0.080729\n",
      "std         0.272419\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.000000\n",
      "75%         0.000000\n",
      "max         1.000000\n",
      "TARGET    0.080729\n",
      "dtype: float64\n",
      "         TARGET\n",
      "count  565372.0\n",
      "mean        0.5\n",
      "std         0.5\n",
      "min         0.0\n",
      "25%         0.0\n",
      "50%         0.5\n",
      "75%         1.0\n",
      "max         1.0\n",
      "TARGET    0.5\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/usr/local/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEICAYAAACqMQjAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAVcklEQVR4nO3df7CmZX3f8fcnrBiKP0C3OWWAZO1kM1OEBnUHSW3TY2hxoVPXtMSBIbIaxk0DdpJm20jS6WAkzmhSdAqj6DrssDgoIvmx24rdMsgZm8YlrNHwy1pOcZXdIhQW0cWoXfz2j+fa5PF4rj3Pnh/P2eW8XzP3nPv53td9X9f17O75nPvHeTZVhSRJs/mx5R6AJOnoZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkS0pAkB4aWHyT5q6HXl7Y2k0kqyTtn7Lum1Q+135Pkqln6uDjJPUmeTfJEW78iSdr2m5J8f8ZY/jLJPxp6/eyMvg4k+cnxvEtaSQwJaUhVvejQAnwd+OdDtVtas43AfuCyzmFOavtfBPyHJP/00IYkm4H/BPwB8HeACeBfAa8Djh86xu8Pj6Wqfraq/vvQ2F453Fdbvr4474L0NwwJ6QgkOZHBN/8rgbVJ1vXaVtVu4EHg7LbvS4F3A1dU1e1V9e0a+GJVXVpV31v6GUhHxpCQjsy/AA4AnwJ2MjirmFWSc4EzgelW+jnghcD2JR6jtGgMCenIbAQ+WVXPAR8HLk7yghltnkzyV8DngQ8Bf9Lqq4Enq+rgoYZJ/izJN9u9j58fOsa/bfVDy7Ylm5F0GIaENKIkpwOvBw7dm9gO/Djwz2Y0XQ28CNgMTAKHQuQpYHWSVYcaVtU/qKqT2rbhf4//sapOGlq6ZyzSUjIkpNG9hcG/mf+c5BvAIwxC4ke+gVfVc1X1fuC7wBWt/Hnge8CG8QxXWrhVczeR1GwEfhf48FDtHOBTSV7e2ee9wJYkH66qbyb5XeBD7XHXncCzwN8HTlzCcUvz5pmENIJ2E/qngA9W1TeGlh0Mbkxf0tn108DTwNsBqur3gd8Efgt4vC0fAd4J/NnQfr8143cgnlySiUlziP/pkCSpxzMJSVKXISFJ6jIkJEldhoQkqet59wjs6tWra82aNfPa99lnn+XEE1fWk4jOeWVwzivDQub8hS984cmq+tsz68+7kFizZg27d++e175TU1NMTk4u7oCOcs55ZXDOK8NC5pzka7PVvdwkSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqet79xvVC3L/vGd561aeXpe8975353yRL0vLzTEKS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlS15whkeT0JHcneSjJg0l+vdXflWRfki+15cKhfX47yXSSryR5w1B9fatNJ7lqqP6KJPe0+ieTHN/qL2yvp9v2NYs6e0nSYY1yJnEQ2FxVZwDnAlcmOaNt+0BVnd2WOwDatouBVwLrgQ8lOS7JccAHgQuAM4BLho7zvnasnwaeBi5v9cuBp1v9A62dJGlM5gyJqnqsqv6irX8b+DJw6mF22QDcWlXfq6qvAtPAOW2ZrqpHqur7wK3AhiQBfgG4ve2/DXjT0LG2tfXbgfNae0nSGBzRPYl2uedVwD2t9I4k9yXZmuTkVjsVeHRot72t1qu/HPhmVR2cUf+hY7Xtz7T2kqQxWDVqwyQvAv4Q+I2q+laSG4BrgGpfrwV+ZUlGOffYNgGbACYmJpiamprXcSZOgM1nHZy74RKY75gX6sCBA8vW93JxziuDc14cI4VEkhcwCIhbquqPAKrq8aHtHwX+S3u5Dzh9aPfTWo1O/SngpCSr2tnCcPtDx9qbZBXw0tb+h1TVFmALwLp162pycnKUaf2I62/ZzrX3j5ybi2rPpZPL0u/U1BTzfb+OVc55ZXDOi2OUp5sC3Ah8uareP1Q/ZajZLwIPtPUdwMXtyaRXAGuBPwfuBda2J5mOZ3Bze0dVFXA3cFHbfyOwfehYG9v6RcBnW3tJ0hiM8mPz64C3APcn+VKr/Q6Dp5POZnC5aQ/wqwBV9WCS24CHGDwZdWVVPQeQ5B3ATuA4YGtVPdiO907g1iS/B3yRQSjRvn4syTSwn0GwSJLGZM6QqKo/BWZ7ouiOw+zzHuA9s9TvmG2/qnqEwdNPM+vfBX5prjFKkpaGv3EtSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdc0ZEklOT3J3koeSPJjk11v9ZUnuTPJw+3pyqyfJdUmmk9yX5NVDx9rY2j+cZONQ/TVJ7m/7XJckh+tDkjQeo5xJHAQ2V9UZwLnAlUnOAK4C7qqqtcBd7TXABcDatmwCboDBN3zgauC1wDnA1UPf9G8A3j603/pW7/UhSRqDOUOiqh6rqr9o698GvgycCmwAtrVm24A3tfUNwM01sAs4KckpwBuAO6tqf1U9DdwJrG/bXlJVu6qqgJtnHGu2PiRJY7DqSBonWQO8CrgHmKiqx9qmbwATbf1U4NGh3fa22uHqe2epc5g+Zo5rE4OzFiYmJpiamjqSaf21iRNg81kH57XvQs13zAt14MCBZet7uTjnlcE5L46RQyLJi4A/BH6jqr7VbhsAUFWVpBZ1ZDMcro+q2gJsAVi3bl1NTk7Oq4/rb9nOtfcfUW4umj2XTi5Lv1NTU8z3/TpWOeeVwTkvjpGebkryAgYBcUtV/VErP94uFdG+PtHq+4DTh3Y/rdUOVz9tlvrh+pAkjcEoTzcFuBH4clW9f2jTDuDQE0obge1D9cvaU07nAs+0S0Y7gfOTnNxuWJ8P7GzbvpXk3NbXZTOONVsfkqQxGOXayuuAtwD3J/lSq/0O8F7gtiSXA18D3ty23QFcCEwD3wHeBlBV+5NcA9zb2r27qva39SuAm4ATgM+0hcP0IUkagzlDoqr+FEhn83mztC/gys6xtgJbZ6nvBs6cpf7UbH1IksbD37iWJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSuuYMiSRbkzyR5IGh2ruS7EvypbZcOLTtt5NMJ/lKkjcM1de32nSSq4bqr0hyT6t/Msnxrf7C9nq6bV+zaLOWJI1klDOJm4D1s9Q/UFVnt+UOgCRnABcDr2z7fCjJcUmOAz4IXACcAVzS2gK8rx3rp4Gngctb/XLg6Vb/QGsnSRqjOUOiqj4H7B/xeBuAW6vqe1X1VWAaOKct01X1SFV9H7gV2JAkwC8At7f9twFvGjrWtrZ+O3Beay9JGpNVC9j3HUkuA3YDm6vqaeBUYNdQm72tBvDojPprgZcD36yqg7O0P/XQPlV1MMkzrf2TMweSZBOwCWBiYoKpqal5TWjiBNh81sG5Gy6B+Y55oQ4cOLBsfS8X57wyOOfFMd+QuAG4Bqj29VrgVxZrUEeqqrYAWwDWrVtXk5OT8zrO9bds59r7F5Kb87fn0sll6Xdqaor5vl/HKue8MjjnxTGvp5uq6vGqeq6qfgB8lMHlJIB9wOlDTU9rtV79KeCkJKtm1H/oWG37S1t7SdKYzCskkpwy9PIXgUNPPu0ALm5PJr0CWAv8OXAvsLY9yXQ8g5vbO6qqgLuBi9r+G4HtQ8fa2NYvAj7b2kuSxmTOaytJPgFMAquT7AWuBiaTnM3gctMe4FcBqurBJLcBDwEHgSur6rl2nHcAO4HjgK1V9WDr4p3ArUl+D/gicGOr3wh8LMk0gxvnFy90spKkIzNnSFTVJbOUb5yldqj9e4D3zFK/A7hjlvoj/M3lquH6d4Ffmmt8kqSl429cS5K6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqmjMkkmxN8kSSB4ZqL0tyZ5KH29eTWz1JrksyneS+JK8e2mdja/9wko1D9dckub/tc12SHK4PSdL4jHImcROwfkbtKuCuqloL3NVeA1wArG3LJuAGGHzDB64GXgucA1w99E3/BuDtQ/utn6MPSdKYzBkSVfU5YP+M8gZgW1vfBrxpqH5zDewCTkpyCvAG4M6q2l9VTwN3AuvbtpdU1a6qKuDmGcearQ9J0pjM957ERFU91ta/AUy09VOBR4fa7W21w9X3zlI/XB+SpDFZtdADVFUlqcUYzHz7SLKJweUtJiYmmJqamlc/EyfA5rMOzmvfhZrvmBfqwIEDy9b3cnHOK4NzXhzzDYnHk5xSVY+1S0ZPtPo+4PShdqe12j5gckZ9qtVPm6X94fr4EVW1BdgCsG7dupqcnOw1Pazrb9nOtfcvODfnZc+lk8vS79TUFPN9v45VznllcM6LY76Xm3YAh55Q2ghsH6pf1p5yOhd4pl0y2gmcn+TkdsP6fGBn2/atJOe2p5oum3Gs2fqQJI3JnD82J/kEg7OA1Un2MnhK6b3AbUkuB74GvLk1vwO4EJgGvgO8DaCq9ie5Bri3tXt3VR26GX4FgyeoTgA+0xYO04ckaUzmDImquqSz6bxZ2hZwZec4W4Gts9R3A2fOUn9qtj4kSePjb1xLkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXQsKiSR7ktyf5EtJdrfay5LcmeTh9vXkVk+S65JMJ7kvyauHjrOxtX84ycah+mva8afbvlnIeCVJR2YxziReX1VnV9W69voq4K6qWgvc1V4DXACsbcsm4AYYhApwNfBa4Bzg6kPB0tq8fWi/9YswXknSiJbictMGYFtb3wa8aah+cw3sAk5KcgrwBuDOqtpfVU8DdwLr27aXVNWuqirg5qFjSZLGYNUC9y/gvyUp4CNVtQWYqKrH2vZvABNt/VTg0aF997ba4ep7Z6n/iCSbGJydMDExwdTU1LwmM3ECbD7r4Lz2Xaj5jnmhDhw4sGx9LxfnvDI458Wx0JD4h1W1L8lPAHcm+Z/DG6uqWoAsqRZOWwDWrVtXk5OT8zrO9bds59r7F/qWzM+eSyeXpd+pqSnm+34dq5zzyuCcF8eCLjdV1b729QngjxncU3i8XSqifX2iNd8HnD60+2mtdrj6abPUJUljMu+QSHJikhcfWgfOBx4AdgCHnlDaCGxv6zuAy9pTTucCz7TLUjuB85Oc3G5Ynw/sbNu+leTc9lTTZUPHkiSNwUKurUwAf9yeSl0FfLyq/muSe4HbklwOfA14c2t/B3AhMA18B3gbQFXtT3INcG9r9+6q2t/WrwBuAk4APtMWSdKYzDskquoR4GdnqT8FnDdLvYArO8faCmydpb4bOHO+Y5QkLYy/cS1J6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqSu5flv2CTpeWrNVZ9etr5vWn/ioh/TMwlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpK6jPiSSrE/ylSTTSa5a7vFI0kpyVIdEkuOADwIXAGcAlyQ5Y3lHJUkrx1EdEsA5wHRVPVJV3wduBTYs85gkacU42v9nulOBR4de7wVeO7NRkk3ApvbyQJKvzLO/1cCT89x3QfK+5egVWMY5LyPnvDKsuDm//n0LmvNPzVY82kNiJFW1Bdiy0OMk2V1V6xZhSMcM57wyOOeVYSnmfLRfbtoHnD70+rRWkySNwdEeEvcCa5O8IsnxwMXAjmUekyStGEf15aaqOpjkHcBO4Dhga1U9uIRdLviS1THIOa8MznllWPQ5p6oW+5iSpOeJo/1ykyRpGRkSkqSuFRkSc33UR5IXJvlk235PkjXLMMxFNcKcfzPJQ0nuS3JXklmfmT6WjPqRLkn+ZZJKckw/LjnKfJO8uf05P5jk4+Me42Ib4e/1Tya5O8kX29/tC5djnIspydYkTyR5oLM9Sa5r78l9SV69oA6rakUtDG6A/2/g7wLHA38JnDGjzRXAh9v6xcAnl3vcY5jz64G/1dZ/bSXMubV7MfA5YBewbrnHvcR/xmuBLwInt9c/sdzjHsOctwC/1tbPAPYs97gXYd4/D7waeKCz/ULgM0CAc4F7FtLfSjyTGOWjPjYA29r67cB5STLGMS62OedcVXdX1Xfay10MfiflWDbqR7pcA7wP+O44B7cERpnv24EPVtXTAFX1xJjHuNhGmXMBL2nrLwX+zxjHtySq6nPA/sM02QDcXAO7gJOSnDLf/lZiSMz2UR+n9tpU1UHgGeDlYxnd0hhlzsMuZ/CTyLFszjm30/DTq+rT4xzYEhnlz/hngJ9J8j+S7EqyfmyjWxqjzPldwC8n2QvcAfzr8QxtWR3pv/fDOqp/T0Ljl+SXgXXAP17usSylJD8GvB946zIPZZxWMbjkNMngTPFzSc6qqm8u56CW2CXATVV1bZKfAz6W5Myq+sFyD+xYsRLPJEb5qI+/bpNkFYPT1KfGMrqlMdLHmyT5J8C/B95YVd8b09iWylxzfjFwJjCVZA+Da7c7juGb16P8Ge8FdlTV/6uqrwL/i0FoHKtGmfPlwG0AVfV54McZfPDf89mifpzRSgyJUT7qYwewsa1fBHy22h2hY9Scc07yKuAjDALiWL9WDXPMuaqeqarVVbWmqtYwuA/zxqravTzDXbBR/l7/CYOzCJKsZnD56ZExjnGxjTLnrwPnAST5ewxC4v+OdZTjtwO4rD3ldC7wTFU9Nt+DrbjLTdX5qI8k7wZ2V9UO4EYGp6XTDG4QXbx8I164Eef8B8CLgE+1e/Rfr6o3LtugF2jEOT9vjDjfncD5SR4CngP+XVUds2fII855M/DRJP+GwU3stx7jP/CR5BMMwn51u9dyNfACgKr6MIN7LxcC08B3gLctqL9j/P2SJC2hlXi5SZI0IkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqev/A8pKmdXGmpQgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = pd.DataFrame(y)\n",
    "test.hist()\n",
    "print(test.describe())\n",
    "print(np.sum(test == 1)/(len(test)))\n",
    "\n",
    "test = pd.DataFrame(y_res)\n",
    "test.hist()\n",
    "print(test.describe())\n",
    "print(np.sum(test == 1)/(len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_res\n",
    "X = X_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column transformer for numerical and categorical features\n",
    "numeric_features = ['FLOORSMAX_MEDI', 'ELEVATORS_MEDI', 'FLOORSMIN_MEDI',\n",
    "       'AMT_CREDIT', 'TOTALAREA_MODE', 'DAYS_EMPLOYED',\n",
    "       'OBS_30_CNT_SOCIAL_CIRCLE', 'CNT_FAM_MEMBERS', 'CNT_CHILDREN',\n",
    "       'OWN_CAR_AGE', 'DAYS_ID_PUBLISH', 'DAYS_LAST_PHONE_CHANGE']  # List of numerical feature column indices\n",
    "categorical_features = ['CODE_GENDER','OCCUPATION_TYPE']  # List of categorical feature column indices\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('replace_values', ReplaceValuesTransformer(column='DAYS_EMPLOYED')),\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "     ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42, shuffle = True)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.15, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_validation = preprocessor.transform(X_validation)\n",
    "X_test = preprocessor.transform(X_test) #Transform test set with the same constants\n",
    "\n",
    "\n",
    "y_train = y_train.to_numpy()\n",
    "y_validation = y_validation.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "# convert numpy arrays to tensors\n",
    "X_train_tensor = torch.from_numpy(X_train)\n",
    "X_valid_tensor = torch.from_numpy(X_validation)\n",
    "X_test_tensor = torch.from_numpy(X_test)\n",
    "y_train_tensor = torch.from_numpy(y_train)\n",
    "y_valid_tensor = torch.from_numpy(y_validation)\n",
    "y_test_tensor = torch.from_numpy(y_test)\n",
    "\n",
    "# create TensorDataset in PyTorch\n",
    "hcdr_train = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "hcdr_valid = torch.utils.data.TensorDataset(X_valid_tensor, y_valid_tensor)\n",
    "hcdr_test = torch.utils.data.TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "# create dataloader\n",
    "# DataLoader is implemented in PyTorch, which will return an iterator to iterate training data by batch.\n",
    "train_batch_size = 96\n",
    "valid_test_batch_size = 64\n",
    "trainloader_hcdr = torch.utils.data.DataLoader(hcdr_train, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "validloader_hcdr = torch.utils.data.DataLoader(hcdr_valid, batch_size=valid_test_batch_size, shuffle=True, num_workers=2)\n",
    "testloader_hcdr = torch.utils.data.DataLoader(hcdr_test, batch_size=valid_test_batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define NN model (Rectified Linear Unit ver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_hcdr_model(\n",
    "    hidden_layer_neurons=[32, 16, 8],\n",
    "    opt=optim.SGD,\n",
    "    epochs=5,\n",
    "    learning_rate=1e-3\n",
    "):\n",
    "\n",
    "    D_in = X_test.shape[1]  # Input layer neurons depend on the input dataset shape\n",
    "    D_out = 2  # Output layer neurons - depend on what you're trying to predict, here, 2 classes: 0 and 1\n",
    "\n",
    "    str_neurons = [str(h) for h in hidden_layer_neurons]\n",
    "    arch_string = f\"{D_in}-{'-'.join(str_neurons)}-{D_out}\"\n",
    "\n",
    "    layers = [\n",
    "        torch.nn.Linear(D_in, hidden_layer_neurons[0]),  # X.matmul(W1)\n",
    "        nn.ReLU(),  # ReLU( X.matmul(W1))\n",
    "    ]\n",
    "\n",
    "    # Add hidden layers\n",
    "    for i in range(1, len(hidden_layer_neurons)):\n",
    "        prev, curr = hidden_layer_neurons[i - 1], hidden_layer_neurons[i]\n",
    "        layers.append(torch.nn.Linear(prev, curr))\n",
    "        layers.append(nn.ReLU())\n",
    "\n",
    "\n",
    "    # Add final layer\n",
    "    layers.append(nn.Linear(hidden_layer_neurons[-1], D_out)) # Relu( X.matmul(W1)).matmul(W2))\n",
    "\n",
    "    # Use the nn package to define our model and loss function.\n",
    "    # use the sequential API makes things simple\n",
    "    model = torch.nn.Sequential(*layers)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # use Cross Entropy and SGD optimizer.\n",
    "    loss_fn = nn.CrossEntropyLoss()  #for classfication\n",
    "    optimizer = opt(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    #summary(model, (4, 20))\n",
    "    print('-'*50)\n",
    "    print('Model:')\n",
    "    print(model)\n",
    "    print('-'*50)\n",
    "\n",
    "    '''\n",
    "    Training Process:\n",
    "        Load a batch of data.\n",
    "        Zero the grad.\n",
    "        Predict the batch of the data through net i.e forward pass.\n",
    "        Calculate the loss value by predict value and true value.\n",
    "        Backprop i.e get the gradient with respect to parameters\n",
    "        Update optimizer i.e gradient update\n",
    "    '''\n",
    "\n",
    "    loss_history = []\n",
    "    acc_history = []\n",
    "    def train_epoch(epoch, model, loss_fn, opt, train_loader):\n",
    "        running_loss = 0.0\n",
    "        count = 0\n",
    "        y_pred = []\n",
    "        epoch_target = []\n",
    "        # dataset API gives us pythonic batching\n",
    "        for batch_id, data in enumerate(train_loader):\n",
    "            inputs, target = data[0].to(device), data[1].to(device)\n",
    "            # 1:zero the grad, 2:forward pass, 3:calculate loss,  and 4:backprop!\n",
    "            opt.zero_grad()\n",
    "            preds = model(inputs.float()) #prediction over the input data\n",
    "\n",
    "            # compute loss and gradients\n",
    "            loss = loss_fn(preds, target)    #mean loss for this batch\n",
    "\n",
    "            loss.backward() #calculate nabla_w\n",
    "            loss_history.append(loss.item())\n",
    "            opt.step()  #update W\n",
    "            y_pred.extend(torch.argmax(preds, dim=1).tolist())\n",
    "            epoch_target.extend(target.tolist())\n",
    "            #from IPython.core.debugger import Pdb as pdb;    pdb().set_trace() #breakpoint; dont forget to quit\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            count += 1\n",
    "\n",
    "        loss = np.round(running_loss/count, 3)\n",
    "\n",
    "        #accuracy\n",
    "        correct = (np.array(y_pred) == np.array(epoch_target))\n",
    "        accuracy = correct.sum() / correct.size\n",
    "        accuracy = np.round(accuracy, 3)\n",
    "        #F1 score\n",
    "        f1 = f1_score(np.array(epoch_target), np.array(y_pred), average='weighted')\n",
    "        f1 = np.round(f1, 3)\n",
    "        #roc_auc score\n",
    "        roc_auc = roc_auc_score(np.array(epoch_target), np.array(y_pred), multi_class='ovo')\n",
    "        roc_auc = np.round(roc_auc, 3)\n",
    "\n",
    "\n",
    "\n",
    "        return loss, accuracy, f1, roc_auc\n",
    "\n",
    "\n",
    "\n",
    "    #from IPython.core.debugger import Pdb as pdb;    pdb().set_trace() #breakpoint; dont forget to quit\n",
    "    def evaluate_model(epoch, model, loss_fn, opt, data_loader, tag = \"Test\"):\n",
    "        overall_loss = 0.0\n",
    "        count = 0\n",
    "        y_pred = []\n",
    "        epoch_target = []\n",
    "        for i,data in enumerate(data_loader):\n",
    "            inputs, target = data[0].to(device), data[1].to(device)\n",
    "            preds = model(inputs.float())\n",
    "\n",
    "            loss = loss_fn(preds, target)           # compute loss value\n",
    "\n",
    "            overall_loss += (loss.item())  # compute total loss to save to logs\n",
    "            y_pred.extend(torch.argmax(preds, dim=1).tolist())\n",
    "            epoch_target.extend(target.tolist())\n",
    "            count += 1\n",
    "\n",
    "        # compute mean loss\n",
    "        loss = np.round(overall_loss/count, 3)\n",
    "        #accuracy\n",
    "        correct = (np.array(y_pred) == np.array(epoch_target))\n",
    "        accuracy = correct.sum() / correct.size\n",
    "        accuracy = np.round(accuracy, 3)\n",
    "        #F1 score\n",
    "        f1 = f1_score(np.array(epoch_target), np.array(y_pred), average='weighted')\n",
    "        f1 = np.round(f1, 3)\n",
    "        #roc_auc score\n",
    "        roc_auc = roc_auc_score(np.array(epoch_target), np.array(y_pred), multi_class='ovo')\n",
    "        roc_auc = np.round(roc_auc, 3)\n",
    "\n",
    "        return loss, accuracy, f1, roc_auc\n",
    "\n",
    "\n",
    "    last_f1 = 0\n",
    "    for epoch in range(epochs):\n",
    "        # print(f\"Epoch {epoch+1}\")\n",
    "        train_loss, train_accuracy, train_f1, train_roc_auc = train_epoch(epoch, model, loss_fn, optimizer, trainloader_hcdr)\n",
    "        valid_loss, valid_accuracy, valid_f1, valid_roc_auc = evaluate_model(epoch, model, loss_fn, optimizer, validloader_hcdr, tag = \"Validation\")\n",
    "        print(f\"Epoch {epoch+1}: Train Accuracy: {train_accuracy}\\t Validation Accuracy: {valid_accuracy} Validation F1 score: {valid_f1} Validation roc_auc score: {valid_roc_auc}\")\n",
    "        if last_f1 == 0:\n",
    "            last_f1 = valid_f1\n",
    "        else:\n",
    "            improvement = (valid_f1 - last_f1) / last_f1\n",
    "\n",
    "            if improvement < 0.01:\n",
    "                break\n",
    "\n",
    "\n",
    "    print(\"-\"*50)\n",
    "    test_loss, test_accuracy, test_f1, test_roc_auc = evaluate_model(epoch, model, loss_fn, opt, testloader_hcdr, tag=\"Test\")\n",
    "\n",
    "    return arch_string, train_accuracy, valid_accuracy, test_accuracy, test_loss, test_f1, test_roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Model:\n",
      "Sequential(\n",
      "  (0): Linear(in_features=34, out_features=100, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n",
      "--------------------------------------------------\n",
      "Epoch 1: Train Accuracy: 0.52\t Validation Accuracy: 0.553 Validation F1 score: 0.533 Validation roc_auc score: 0.553\n",
      "Epoch 2: Train Accuracy: 0.571\t Validation Accuracy: 0.582 Validation F1 score: 0.582 Validation roc_auc score: 0.582\n",
      "Epoch 3: Train Accuracy: 0.584\t Validation Accuracy: 0.588 Validation F1 score: 0.588 Validation roc_auc score: 0.588\n",
      "Epoch 4: Train Accuracy: 0.588\t Validation Accuracy: 0.59 Validation F1 score: 0.59 Validation roc_auc score: 0.59\n",
      "Epoch 5: Train Accuracy: 0.59\t Validation Accuracy: 0.592 Validation F1 score: 0.592 Validation roc_auc score: 0.592\n",
      "Epoch 6: Train Accuracy: 0.591\t Validation Accuracy: 0.593 Validation F1 score: 0.593 Validation roc_auc score: 0.593\n",
      "Epoch 7: Train Accuracy: 0.592\t Validation Accuracy: 0.595 Validation F1 score: 0.595 Validation roc_auc score: 0.595\n",
      "Epoch 8: Train Accuracy: 0.594\t Validation Accuracy: 0.596 Validation F1 score: 0.596 Validation roc_auc score: 0.596\n",
      "Epoch 9: Train Accuracy: 0.595\t Validation Accuracy: 0.597 Validation F1 score: 0.597 Validation roc_auc score: 0.597\n",
      "Epoch 10: Train Accuracy: 0.595\t Validation Accuracy: 0.597 Validation F1 score: 0.597 Validation roc_auc score: 0.597\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Architecture string</th>\n",
       "      <th>Optimizer</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Train accuracy</th>\n",
       "      <th>Valid accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "      <th>test F1 score</th>\n",
       "      <th>test ROC_AUC score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34-50-50-25-2</td>\n",
       "      <td>&lt;class 'torch.optim.adadelta.Adadelta'&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>56.6%</td>\n",
       "      <td>57.4%</td>\n",
       "      <td>57.4%</td>\n",
       "      <td>57.1%</td>\n",
       "      <td>57.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34-100-100-2</td>\n",
       "      <td>&lt;class 'torch.optim.adadelta.Adadelta'&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>59.5%</td>\n",
       "      <td>59.7%</td>\n",
       "      <td>59.5%</td>\n",
       "      <td>59.5%</td>\n",
       "      <td>59.5%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Architecture string                                Optimizer Epochs  \\\n",
       "0       34-50-50-25-2  <class 'torch.optim.adadelta.Adadelta'>      5   \n",
       "1        34-100-100-2  <class 'torch.optim.adadelta.Adadelta'>     10   \n",
       "\n",
       "  Train accuracy Valid accuracy Test accuracy test F1 score test ROC_AUC score  \n",
       "0          56.6%          57.4%         57.4%         57.1%              57.4%  \n",
       "1          59.5%          59.7%         59.5%         59.5%              59.5%  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#==================================================#\n",
    "#    Modify START   #\n",
    "#==================================================#\n",
    "'''\n",
    "(hidden_layers_neurons) - A list of the number of neurons in the hidden layers in order. DEFAULT: [32, 16, 8] => 1st hidden layer: 32 neurons, 2nd: 16, 3rd: 8\n",
    "(opt) - The optimizer function to use: SGD, Adam, etc.,  DEFAULT: optim.SGD\n",
    "(epochs) - The total number of epochs to train your model for,  DEFAULT: 5\n",
    "(learning_rate) - The learning rate to take the gradient descent step with\n",
    "'''\n",
    "\n",
    "hidden_layer_neurons = [100, 100]\n",
    "opt = optim.Adadelta\n",
    "epochs = 10\n",
    "learning_rate = 1e-3\n",
    "\n",
    "#==================================================#\n",
    "#    Modify END #\n",
    "#==================================================#\n",
    "\n",
    "arch_string, train_accuracy, valid_accuracy, test_accuracy, test_loss, test_f1, test_roc_auc = run_hcdr_model(\n",
    "    hidden_layer_neurons,\n",
    "    opt,\n",
    "    epochs,\n",
    "    learning_rate\n",
    ")\n",
    "\n",
    "\n",
    "try: hcdrLog\n",
    "except : hcdrLog = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"Architecture string\",\n",
    "        \"Optimizer\",\n",
    "        \"Epochs\",\n",
    "        \"Train accuracy\",\n",
    "        \"Valid accuracy\",\n",
    "        \"Test accuracy\",\n",
    "        \"test F1 score\",\n",
    "        \"test ROC_AUC score\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "hcdrLog.loc[len(hcdrLog)] = [\n",
    "    arch_string,\n",
    "    f\"{opt}\",\n",
    "    f\"{epochs}\",\n",
    "    f\"{np.round((train_accuracy * 100),3)}%\",\n",
    "    f\"{np.round((valid_accuracy * 100),3)}%\",\n",
    "    f\"{np.round((test_accuracy * 100),3)}%\",\n",
    "    f\"{np.round((test_f1 * 100),3)}%\",\n",
    "    f\"{np.round((test_roc_auc * 100),3)}%\",\n",
    "]\n",
    "\n",
    "hcdrLog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22OL7h2poQ53"
   },
   "source": [
    "## Architecture 2\n",
    "\n",
    "Our second neural network uses the SGD optimizer and various numbers of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "3VCtHSxiodPY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Model:\n",
      "Sequential(\n",
      "  (0): Linear(in_features=34, out_features=200, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=100, out_features=50, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=50, out_features=2, bias=True)\n",
      ")\n",
      "--------------------------------------------------\n",
      "Epoch 1: Train Accuracy: 0.523\t Validation Accuracy: 0.562 Validation F1 score: 0.56 Validation roc_auc score: 0.562\n",
      "Epoch 2: Train Accuracy: 0.572\t Validation Accuracy: 0.577 Validation F1 score: 0.577 Validation roc_auc score: 0.577\n",
      "Epoch 3: Train Accuracy: 0.58\t Validation Accuracy: 0.583 Validation F1 score: 0.583 Validation roc_auc score: 0.583\n",
      "Epoch 4: Train Accuracy: 0.584\t Validation Accuracy: 0.588 Validation F1 score: 0.588 Validation roc_auc score: 0.588\n",
      "Epoch 5: Train Accuracy: 0.588\t Validation Accuracy: 0.592 Validation F1 score: 0.591 Validation roc_auc score: 0.592\n",
      "Epoch 6: Train Accuracy: 0.591\t Validation Accuracy: 0.595 Validation F1 score: 0.595 Validation roc_auc score: 0.595\n",
      "Epoch 7: Train Accuracy: 0.594\t Validation Accuracy: 0.598 Validation F1 score: 0.597 Validation roc_auc score: 0.598\n",
      "Epoch 8: Train Accuracy: 0.596\t Validation Accuracy: 0.599 Validation F1 score: 0.599 Validation roc_auc score: 0.599\n",
      "Epoch 9: Train Accuracy: 0.597\t Validation Accuracy: 0.601 Validation F1 score: 0.601 Validation roc_auc score: 0.601\n",
      "Epoch 10: Train Accuracy: 0.599\t Validation Accuracy: 0.602 Validation F1 score: 0.602 Validation roc_auc score: 0.602\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Architecture string</th>\n",
       "      <th>Optimizer</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Train accuracy</th>\n",
       "      <th>Valid accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "      <th>test F1 score</th>\n",
       "      <th>test ROC_AUC score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34-50-50-25-2</td>\n",
       "      <td>&lt;class 'torch.optim.adadelta.Adadelta'&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>56.6%</td>\n",
       "      <td>57.4%</td>\n",
       "      <td>57.4%</td>\n",
       "      <td>57.1%</td>\n",
       "      <td>57.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34-100-100-2</td>\n",
       "      <td>&lt;class 'torch.optim.adadelta.Adadelta'&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>59.5%</td>\n",
       "      <td>59.7%</td>\n",
       "      <td>59.5%</td>\n",
       "      <td>59.5%</td>\n",
       "      <td>59.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34-100-100-2</td>\n",
       "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>60.0%</td>\n",
       "      <td>60.4%</td>\n",
       "      <td>60.2%</td>\n",
       "      <td>60.2%</td>\n",
       "      <td>60.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34-34-34-17-2</td>\n",
       "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>59.2%</td>\n",
       "      <td>59.4%</td>\n",
       "      <td>59.1%</td>\n",
       "      <td>59.0%</td>\n",
       "      <td>59.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34-200-100-2</td>\n",
       "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>60.2%</td>\n",
       "      <td>60.4%</td>\n",
       "      <td>60.3%</td>\n",
       "      <td>60.3%</td>\n",
       "      <td>60.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34-200-100-50-2</td>\n",
       "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>59.9%</td>\n",
       "      <td>60.2%</td>\n",
       "      <td>60.0%</td>\n",
       "      <td>60.0%</td>\n",
       "      <td>60.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Architecture string                                Optimizer Epochs  \\\n",
       "0       34-50-50-25-2  <class 'torch.optim.adadelta.Adadelta'>      5   \n",
       "1        34-100-100-2  <class 'torch.optim.adadelta.Adadelta'>     10   \n",
       "2        34-100-100-2            <class 'torch.optim.sgd.SGD'>     10   \n",
       "3       34-34-34-17-2            <class 'torch.optim.sgd.SGD'>     10   \n",
       "4        34-200-100-2            <class 'torch.optim.sgd.SGD'>     10   \n",
       "5     34-200-100-50-2            <class 'torch.optim.sgd.SGD'>     10   \n",
       "\n",
       "  Train accuracy Valid accuracy Test accuracy test F1 score test ROC_AUC score  \n",
       "0          56.6%          57.4%         57.4%         57.1%              57.4%  \n",
       "1          59.5%          59.7%         59.5%         59.5%              59.5%  \n",
       "2          60.0%          60.4%         60.2%         60.2%              60.2%  \n",
       "3          59.2%          59.4%         59.1%         59.0%              59.1%  \n",
       "4          60.2%          60.4%         60.3%         60.3%              60.3%  \n",
       "5          59.9%          60.2%         60.0%         60.0%              60.0%  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#==================================================#\n",
    "#    Modify START   #\n",
    "#==================================================#\n",
    "'''\n",
    "(hidden_layers_neurons) - A list of the number of neurons in the hidden layers in order. DEFAULT: [32, 16, 8] => 1st hidden layer: 32 neurons, 2nd: 16, 3rd: 8\n",
    "(opt) - The optimizer function to use: SGD, Adam, etc.,  DEFAULT: optim.SGD\n",
    "(epochs) - The total number of epochs to train your model for,  DEFAULT: 5\n",
    "(learning_rate) - The learning rate to take the gradient descent step with\n",
    "'''\n",
    "\n",
    "hidden_layer_neurons = [200, 100, 50]\n",
    "opt = optim.SGD\n",
    "epochs = 10\n",
    "learning_rate = 1e-3\n",
    "\n",
    "#==================================================#\n",
    "#    Modify END #\n",
    "#==================================================#\n",
    "\n",
    "arch_string, train_accuracy, valid_accuracy, test_accuracy, test_loss, test_f1, test_roc_auc = run_hcdr_model(\n",
    "    hidden_layer_neurons,\n",
    "    opt,\n",
    "    epochs,\n",
    "    learning_rate\n",
    ")\n",
    "\n",
    "\n",
    "try: hcdrLog\n",
    "except : hcdrLog = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"Architecture string\",\n",
    "        \"Optimizer\",\n",
    "        \"Epochs\",\n",
    "        \"Train accuracy\",\n",
    "        \"Valid accuracy\",\n",
    "        \"Test accuracy\",\n",
    "        \"test F1 score\",\n",
    "        \"test ROC_AUC score\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "hcdrLog.loc[len(hcdrLog)] = [\n",
    "    arch_string,\n",
    "    f\"{opt}\",\n",
    "    f\"{epochs}\",\n",
    "    f\"{np.round((train_accuracy * 100),3)}%\",\n",
    "    f\"{np.round((valid_accuracy * 100),3)}%\",\n",
    "    f\"{np.round((test_accuracy * 100),3)}%\",\n",
    "    f\"{np.round((test_f1 * 100),3)}%\",\n",
    "    f\"{np.round((test_roc_auc * 100),3)}%\",\n",
    "]\n",
    "\n",
    "hcdrLog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Nby148XGByn"
   },
   "source": [
    "# Data Leakage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQ7V72r3GHiV"
   },
   "source": [
    "We suspected some degree of data leakage, due to the relatively high accuracies in comparison to middling ROC AUC scores. Part of this was, likely in large part, caused by a large class imbalance of repayments versus failures to repay in the training data. After we rebalanced using over/under-sampling techniques, these performance issues persisted thus we began to do root cause analysis to trace the data leakage. We examined two potential sources: multicollinearity and autocorrelation among the features; and high correlation between any of the features and the target variable. We found no instances of very high correlation between the predictors and the target, all having correlation coefficients below 0.2. In terms of the multicollinearity analysis, we examined the correlation matrix of the feature variables and found ELEVATORS_MEDI, FLOORSMIN_MEDI, AND TOTALAREA_MODE to be very highly correlation (> ~70%) to the FLOORSMAX_MEDI feature. However, dropping these variables and rerunning our models on the updated train set did not yield any substantial performance improvements.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4MO97X6TWIh"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OjwSN7shobAS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RkEXh4ciGM6o"
   },
   "source": [
    "# Modeling Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NK4fgnZlGSJo"
   },
   "source": [
    "## delete me\n",
    "\n",
    "Modeling Pipelines (HCDR)\n",
    "-- A visualization of the modeling pipeline (s) and subpipelines if necessary\n",
    "-- Families of input features and count per family\n",
    "-- Number of input features\n",
    "-- Hyperparameters and settings considered\n",
    "-- Loss function used (data loss and regularization parts) in latex\n",
    "-- Number of experiments conducted\n",
    "-- Experiment table with the following details per experiment:\n",
    "----- Baseline experiment\n",
    "----- Any additional experiments\n",
    "----- Final model tuned\n",
    "----- best results (1 to three) for all experiments you conducted with the following details\n",
    "---- The families of input features used\n",
    "----- For train/valid/test record the following in a Pandas DataFrame:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1b-AnF-GXzo"
   },
   "source": [
    "# Results and Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WI28NRCHGbSR"
   },
   "source": [
    "After training several different neural network model architectures, the test ROC AUC score did not see any improvement above the 60% level.\n",
    "\n",
    "The best performing model was: 34-200-100-2 using 'torch.optim.sgd.SGD'\n",
    "\n",
    "We can only speculate as to why the model did not improve. The model could be overfitting and using the same random seed could be preventing more variation in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-LWLARF2GiH4"
   },
   "source": [
    "# Conclusion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JS5O5gMGnmR"
   },
   "source": [
    "## delete me\n",
    "\n",
    "Expectations here are to address the following following in your conclusion (in about 150 words) in a main section by itself:\n",
    "\n",
    "-- Restate your project focus explain why it’s important. Make sure that this part of the conclusion is concise and clear.\n",
    "\n",
    "-- Restate your hypothesis (e.g., ML pipelines with custom features can accurately predict HCDR or Cats/Dogs)\n",
    "\n",
    "-- Summarize main points of your project: Remind your readers your key points. (e.g, best features, best model, hyper-parameters and so on)\n",
    "\n",
    "-- Discuss the significance of your results\n",
    "\n",
    "-- Discuss the future of your project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit assignment plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](Phase_4_Credit_Assignment.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
