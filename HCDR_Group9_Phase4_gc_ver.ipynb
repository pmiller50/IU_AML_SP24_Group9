{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "339a04cf-335a-4c61-bec8-916bf7fd3d3b"
      },
      "source": [
        "# Final Project Phase 4 - Home Credit Default Risk\n",
        "\n",
        "Spring 2024\n",
        "\n",
        "**Team Members:**\n",
        "- Glen Colletti\n",
        "- Alex Bordanca\n",
        "- Paul Miller\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Abstract\n",
        "\n"
      ],
      "metadata": {
        "id": "fKtFKCSXGwK3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## delete me\n",
        "\n",
        "Abstract (150 words approximately describing this phase and the previous phases of the project): that details the problem you are tackling, the main goal of the project, feature engineering, what you did (main experiments), what were your results/findings (best pipeline and the corresponding public, private scores)\""
      ],
      "metadata": {
        "id": "Gv40syCsG00K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our project aimed to predict loan repayment based on the data available at the time of application. To accomplish this the team down selected features in the application train data; implemented Recency, Frequency, and Monetary Value features; trained KNN, XGBoost, and Linear Regression models; as well as a deep learning model. We attempted to account for this by oversampling the minority class. Along the way we discovered an imbalance in the TARGET data causing our models to overpredict the majority class. The team identified correlations among the training set features, motivating us to select only one of any set of correlated features, reducing our model complexity with minimal impact on predictions. Other data anomalies included erroneous entries implying 1000-year credit history, and features with missing data. Mitigations for these anomalies included removal and imputing. By building our mitigations into data pipelines we were able to generalize our data preprocessing to our four model types with minimal rework. [BLAH BLAH] model yielded the strongest prediction performance with [SCORES SCORES SCORES].  "
      ],
      "metadata": {
        "id": "sn3pYxCPG38p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network"
      ],
      "metadata": {
        "id": "RSkIe-ObFrva"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## delete me\n",
        "\n",
        "Neural Network/PyTorch (HCDR)\n",
        "-- Implement Neural Network (NN) model\n",
        "-- Experiment with at least 2 different Network architecture.\n",
        "-- Report neural network architecture in string form (e.g., 100 - 200 - Relu - 300 - Relu - 2 Softmax )"
      ],
      "metadata": {
        "id": "mtwjw19HFzrB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To implement the Neural Network (Deep Learning) models a pipeline was adapted from Homework 11. The pipeline allowed us to train and test Neural Networks with dynamically defined hidden layers, optimization functions, activation functions, and loss functions. We improved upon the intial code base by adding F1 scores and AUC_ROC scores. A feature was added for the code to exit the epoch training cycle if subsequent models were no longer improving, indicating the model had converged.\n",
        "\n",
        "Intially we faced challenges with models hitting a performance ceiling around 92% accuracy. Upon further inspection we realized the models were learning to over predict the majoirty class becuase the TARGET data was 92% majority class. After added an oversampling step to the data processing to balance the majority and minority class the models hit a ceiling of ~60% performance."
      ],
      "metadata": {
        "id": "bCwg3q-lm_QQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Network Pipeline"
      ],
      "metadata": {
        "id": "LwsOfjODqARV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OlUYJGVlp-Un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Architecture 1\n",
        "\n",
        "things and stuff about our first Network"
      ],
      "metadata": {
        "id": "0UW7aoGHn_NV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kpKvxUVNoQUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Architecture 2\n",
        "\n",
        "things and stuff about our second Network"
      ],
      "metadata": {
        "id": "22OL7h2poQ53"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3VCtHSxiodPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Leakage"
      ],
      "metadata": {
        "id": "8Nby148XGByn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## delete me\n",
        "\n",
        "Leakage (HCDR)\n",
        "-- Go through your Pipeline and check if there is any leakage.\n",
        "-- Are you violating any cardinal sins of ML?\n",
        "-- Describe how your pipeline does not suffer from any leakage problem and does not violate any cardinal sins of ML"
      ],
      "metadata": {
        "id": "wQ7V72r3GHiV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OjwSN7shobAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling Pipelines"
      ],
      "metadata": {
        "id": "RkEXh4ciGM6o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## delete me\n",
        "\n",
        "Modeling Pipelines (HCDR)\n",
        "-- A visualization of the modeling pipeline (s) and subpipelines if necessary\n",
        "-- Families of input features and count per family\n",
        "-- Number of input features\n",
        "-- Hyperparameters and settings considered\n",
        "-- Loss function used (data loss and regularization parts) in latex\n",
        "-- Number of experiments conducted\n",
        "-- Experiment table with the following details per experiment:\n",
        "----- Baseline experiment\n",
        "----- Any additional experiments\n",
        "----- Final model tuned\n",
        "----- best results (1 to three) for all experiments you conducted with the following details\n",
        "---- The families of input features used\n",
        "----- For train/valid/test record the following in a Pandas DataFrame:"
      ],
      "metadata": {
        "id": "NK4fgnZlGSJo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results and Discussion"
      ],
      "metadata": {
        "id": "v1b-AnF-GXzo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## delete me\n",
        "\n",
        "Expectations here are to provide the following in sections and subsections:\n",
        "\n",
        "\n",
        "Discussion’s aim is result interpretation, which means explain, analyse, and compare them (results from all the phases). Often, this part is the most important, simply because it lets the researcher take a step back and give a broader look at all experiments conducted. Do not discuss any outcomes not presented in the results part."
      ],
      "metadata": {
        "id": "WI28NRCHGbSR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "\n"
      ],
      "metadata": {
        "id": "-LWLARF2GiH4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## delete me\n",
        "\n",
        "Expectations here are to address the following following in your conclusion (in about 150 words) in a main section by itself:\n",
        "\n",
        "-- Restate your project focus explain why it’s important. Make sure that this part of the conclusion is concise and clear.\n",
        "\n",
        "-- Restate your hypothesis (e.g., ML pipelines with custom features can accurately predict HCDR or Cats/Dogs)\n",
        "\n",
        "-- Summarize main points of your project: Remind your readers your key points. (e.g, best features, best model, hyper-parameters and so on)\n",
        "\n",
        "-- Discuss the significance of your results\n",
        "\n",
        "-- Discuss the future of your project"
      ],
      "metadata": {
        "id": "-JS5O5gMGnmR"
      }
    }
  ]
}